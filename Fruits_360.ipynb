{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import os\n",
    "import scipy.misc\n",
    "from scipy.misc import imread, imresize\n",
    "from keras import regularizers\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get training and validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_images(path):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "    idx_to_label = []\n",
    "    i = -1\n",
    "    for fruit in os.listdir(path):\n",
    "        fruit_path = os.path.join(path,fruit)\n",
    "        labels.append(fruit)\n",
    "        i = i+1\n",
    "        for img in os.listdir(fruit_path):\n",
    "            img_path = os.path.join(fruit_path,img)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, (64, 64))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            img_data.append(image)\n",
    "            idx_to_label.append(i)\n",
    "    return np.array(img_data),np.array(idx_to_label),labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32426, 64, 64, 3)\n",
      "(32426,)\n",
      "['Apple Braeburn', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Red', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Clementine', 'Cocos', 'Dates', 'Granadilla', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Huckleberry', 'Kaki', 'Kiwi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Litchi', 'Mandarine', 'Mango', 'Maracuja', 'Melon Piel de Sapo', 'Nectarine', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach Flat', 'Pear', 'Pear Abate', 'Pear Monster', 'Pear Williams', 'Pepino', 'Pineapple', 'Pitahaya Red', 'Plum', 'Pomegranate', 'Quince', 'Raspberry', 'Salak', 'Strawberry', 'Tamarillo', 'Tangelo']\n"
     ]
    }
   ],
   "source": [
    "trn_data_path = 'C:/Users/Pushkar/Downloads/Datasets/fruits-360/Training'\n",
    "val_data_path = 'C:/Users/Pushkar/Downloads/Datasets/fruits-360/Validation'\n",
    "X_train,y_train,label_data = load_images(trn_data_path)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(label_data)\n",
    "X_test,y_test,label_data_garbage = load_images(val_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_classes = 65\n",
    "Y_train = np_utils.to_categorical(y_train, num_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_of_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.\n",
    "I played around with the dropout values and achieved better score at 0.7\n",
    "activations can be Relu, elu, LeakyRelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(64,64,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3 )))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(65))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 62, 62, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 62, 62, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 62, 62, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 60, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 60, 60, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 65)                33345     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 65)                0         \n",
      "=================================================================\n",
      "Total params: 890,897\n",
      "Trainable params: 889,553\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32426 samples, validate on 10903 samples\n",
      "Epoch 1/1\n",
      "32426/32426 [==============================] - 29s 879us/step - loss: 0.0816 - acc: 0.9735 - val_loss: 0.1690 - val_acc: 0.9431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df7d3dc6a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs=1,batch_size = 32,\n",
    "                    validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32426 samples, validate on 10903 samples\n",
      "Epoch 1/1\n",
      "32426/32426 [==============================] - 28s 878us/step - loss: 0.0561 - acc: 0.9812 - val_loss: 0.1440 - val_acc: 0.9487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df7d3dc390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs=1,batch_size = 32,\n",
    "                    validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10903/10903 [==============================] - 4s 327us/step\n",
      "\n",
      "Test loss:  0.14403905968\n",
      "Test Accuracy 0.94872970742\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test loss: ', score[0])\n",
    "print('Test Accuracy', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "sub.to_csv('./output_cnn.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(width_shift_range=.2, \n",
    "                             height_shift_range=.2,\n",
    "                         zoom_range = 0.1,\n",
    "                        horizontal_flip = 'True')\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=32)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1014/1014 [==============================] - 42s 42ms/step - loss: 0.8392 - acc: 0.7528 - val_loss: 0.3080 - val_acc: 0.8921\n",
      "Epoch 2/5\n",
      "1014/1014 [==============================] - 40s 40ms/step - loss: 0.3594 - acc: 0.8765 - val_loss: 0.3118 - val_acc: 0.8920\n",
      "Epoch 3/5\n",
      "1014/1014 [==============================] - 41s 41ms/step - loss: 0.2503 - acc: 0.9111 - val_loss: 0.3371 - val_acc: 0.8976\n",
      "Epoch 4/5\n",
      "1014/1014 [==============================] - 41s 40ms/step - loss: 0.2237 - acc: 0.9218 - val_loss: 0.0713 - val_acc: 0.9683\n",
      "Epoch 5/5\n",
      "1014/1014 [==============================] - 42s 41ms/step - loss: 0.1994 - acc: 0.9301 - val_loss: 0.1077 - val_acc: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df32362f98>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=5, \n",
    "                    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
